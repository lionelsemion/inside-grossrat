{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "with open(\"merged_votes.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "id_names = []\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "def norm(vote):\n",
    "    vote = int(vote)\n",
    "    if vote == 0:\n",
    "        return (0, 1)\n",
    "    elif vote == 1:\n",
    "        return (1, 1)\n",
    "    elif vote == 2:\n",
    "        return (-1, 1)\n",
    "    else:\n",
    "        return (0, 0)\n",
    "\n",
    "for person in data:\n",
    "    id_names.append(\n",
    "        {\n",
    "            \"id\": person[\"id\"],\n",
    "            \"first_name\": person[\"first_name\"],\n",
    "            \"last_name\": person[\"last_name\"],\n",
    "        }\n",
    "    )\n",
    "    X.append([item for vote in person[\"votes\"] for item in norm(vote)])\n",
    "    Y.append(person[\"spider\"])\n",
    "\n",
    "    id_names, X, Y = shuffle(id_names, X, Y, random_state=42)\n",
    "\n",
    "id_names = pd.DataFrame(id_names)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "display(id_names.head())\n",
    "display(X.head())\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays\n",
    "X_np = X.values.astype('float32')\n",
    "Y_np = Y.values.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, Y.shape[1]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_variant(i, X_train, Y_train, X_test, Y_test):\n",
    "    # Convert to torch tensors\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    Y_train_tensor = torch.tensor(Y_train)\n",
    "    X_test_tensor = torch.tensor(X_test)\n",
    "    Y_test_tensor = torch.tensor(Y_test)\n",
    "\n",
    "    model = SimpleNN()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, Y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, Y_test_tensor)\n",
    "        print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "    print(Y_test_tensor[0])\n",
    "    print(test_outputs[0])\n",
    "\n",
    "    return test_outputs\n",
    "\n",
    "group_count = X_np.shape[0] // GROUP_SIZE\n",
    "\n",
    "X_group = np.array_split(X_np, group_count, axis=0)\n",
    "Y_group = np.array_split(Y_np, group_count, axis=0)\n",
    "\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for i in range(group_count):\n",
    "    print(f\"Training variant {i+1}/{group_count}...\")\n",
    "    # Combine all groups except the current one for training\n",
    "    X_train = np.concatenate([X_group[j] for j in range(group_count) if j != i])\n",
    "    Y_train = np.concatenate([Y_group[j] for j in range(group_count) if j != i])\n",
    "\n",
    "    # Use the current group for testing\n",
    "    X_test = X_group[i]\n",
    "    Y_test = Y_group[i]\n",
    "\n",
    "    all_outputs.append(train_variant(i, X_train, Y_train, X_test, Y_test))\n",
    "\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_np[1])\n",
    "print(all_outputs[1])\n",
    "print(id_names.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataFrame for export\n",
    "spiders_votes_df = id_names.copy()\n",
    "for idx in range(4):\n",
    "    spiders_votes_df[str(idx)] = all_outputs[:, idx]\n",
    "\n",
    "spiders_votes_df = spiders_votes_df.sort_values(by=[\"first_name\", \"last_name\"]).reset_index(drop=True)\n",
    "\n",
    "spiders_votes_df.to_csv(\"spiders_votes.csv\", columns=[\"id\", \"first_name\", \"last_name\", \"0\", \"1\", \"2\", \"3\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
